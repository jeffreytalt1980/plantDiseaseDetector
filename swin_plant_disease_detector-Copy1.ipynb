{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00d2b28-3b69-46b9-9c64-318891e25ff7",
   "metadata": {},
   "source": [
    "## SWIN Transformer Plant Disease Detector Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91190e-94b1-489a-a5cd-b33848fce8d4",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad0cc080-b065-4d61-9f77-fc019bcadee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import keras_cv\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32c225-58e0-4293-9009-814e1ce54a3a",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cde0f4d9-efdf-4f3a-beb5-5f4b6ef55729",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"PlantVillage\"\n",
    "seed_value = 27\n",
    "class_names = ['Apple___Apple_scab',\n",
    " 'Apple___Black_rot',\n",
    " 'Apple___Cedar_apple_rust',\n",
    " 'Apple___healthy',\n",
    " 'Blueberry___healthy',\n",
    " 'Cherry_(including_sour)___Powdery_mildew',\n",
    " 'Cherry_(including_sour)___healthy',\n",
    " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
    " 'Corn_(maize)___Common_rust_',\n",
    " 'Corn_(maize)___Northern_Leaf_Blight',\n",
    " 'Corn_(maize)___healthy',\n",
    " 'Grape___Black_rot',\n",
    " 'Grape___Esca_(Black_Measles)',\n",
    " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
    " 'Grape___healthy',\n",
    " 'Orange___Haunglongbing_(Citrus_greening)',\n",
    " 'Peach___Bacterial_spot',\n",
    " 'Peach___healthy',\n",
    " 'Pepper,_bell___Bacterial_spot',\n",
    " 'Pepper,_bell___healthy',\n",
    " 'Potato___Early_blight',\n",
    " 'Potato___Late_blight',\n",
    " 'Potato___healthy',\n",
    " 'Raspberry___healthy',\n",
    " 'Soybean___healthy',\n",
    " 'Squash___Powdery_mildew',\n",
    " 'Strawberry___Leaf_scorch',\n",
    " 'Strawberry___healthy',\n",
    " 'Tomato___Bacterial_spot',\n",
    " 'Tomato___Early_blight',\n",
    " 'Tomato___Late_blight',\n",
    " 'Tomato___Leaf_Mold',\n",
    " 'Tomato___Septoria_leaf_spot',\n",
    " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
    " 'Tomato___Target_Spot',\n",
    " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
    " 'Tomato___Tomato_mosaic_virus',\n",
    " 'Tomato___healthy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe550a-9fc9-4f3e-9f7c-1a0126ae36dc",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a1a8280e-a112-4786-a811-b3b0ac8b1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "image_dimension = 32 # 224\n",
    "window_size = 2\n",
    "shift_size = 1\n",
    "\n",
    "input_shape = (image_dimension, image_dimension, 3)\n",
    "image_size = (image_dimension, image_dimension)\n",
    "patch_size = (window_size, window_size)\n",
    "\n",
    "dropout_rate = 0.03\n",
    "number_of_heads = 8\n",
    "embedding_dimension = 64\n",
    "number_of_MLP = 256\n",
    "\n",
    "qkv_bias = True\n",
    "\n",
    "number_of_patches_x = input_shape[0] // patch_size[0]\n",
    "number_of_patches_y = input_shape[1] // patch_size[1]\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "number_of_epochs = 10\n",
    "\n",
    "validation_split = .03\n",
    "weight_decay = 0.0001\n",
    "label_smoothing = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e027a-9ed6-478c-8996-6dbbc0415b96",
   "metadata": {},
   "source": [
    "#### Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7eb58e04-26e4-4d6e-926a-d144712d77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    " def window_partition(x, window_size):\n",
    "    _, height, width, channels = x.shape\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.keras.ops.reshape(\n",
    "        x,\n",
    "        (\n",
    "            -1,\n",
    "            number_of_patches_y,\n",
    "            window_size,\n",
    "            number_of_patches_x,\n",
    "            window_size,\n",
    "            channels,\n",
    "        ),\n",
    "    )\n",
    "    x = tf.keras.ops.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.keras.ops.reshape(x, (-1, window_size, window_size, channels))\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.keras.ops.reshape(\n",
    "        windows,\n",
    "        (\n",
    "            -1,\n",
    "            number_of_patches_x,\n",
    "            number_of_patches_y,\n",
    "            window_size,\n",
    "            window_size,\n",
    "            channels,\n",
    "        ),\n",
    "    )\n",
    "    x = tf.keras.ops.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    x = tf.keras.ops.reshape(x, (-1, height, width, channels))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499bc5c-3139-413b-8222-9333b109cde3",
   "metadata": {},
   "source": [
    "#### Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e79ca62b-0c94-4154-8e5a-04983b09f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimension,\n",
    "        window_size,\n",
    "        number_of_heads,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dimension = dimension\n",
    "        self.window_size = window_size\n",
    "        self.number_of_heads = number_of_heads\n",
    "        self.scale = (dimension // number_of_heads) ** -0.5\n",
    "        self.qkv = tf.keras.layers.Dense(dimension * 3, use_bias=qkv_bias)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.proj = tf.keras.layers.Dense(dimension)\n",
    "\n",
    "        number_of_window_elements = (2 * self.window_size[0] - 1) * (\n",
    "            2 * self.window_size[1] - 1\n",
    "        )\n",
    "        self.relative_position_bias_table = self.add_weight(\n",
    "            shape=(number_of_window_elements, self.number_of_heads),\n",
    "            initializer=tf.keras.initializers.Zeros(),\n",
    "            trainable=True,\n",
    "        )\n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
    "        coords = np.stack(coords_matrix)\n",
    "        coords_flatten = coords.reshape(2, -1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "        self.relative_position_index = tf.keras.Variable(\n",
    "            initializer=relative_position_index,\n",
    "            shape=relative_position_index.shape,\n",
    "            dtype=\"int\",\n",
    "            trainable=False,\n",
    "        )\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dimensions = channels // self.number_of_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.keras.ops.reshape(x_qkv, (-1, size, 3, self.number_of_heads, head_dimensions))\n",
    "        x_qkv = tf.keras.ops.transpose(x_qkv, (2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.keras.ops.transpose(k, (0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
    "        relative_position_index_flat = tf.keras.ops.reshape(self.relative_position_index, (-1,))\n",
    "        relative_position_bias = tf.keras.ops.take(\n",
    "            self.relative_position_bias_table,\n",
    "            relative_position_index_flat,\n",
    "            axis=0,\n",
    "        )\n",
    "        relative_position_bias = tf.keras.ops.reshape(\n",
    "            relative_position_bias,\n",
    "            (num_window_elements, num_window_elements, -1),\n",
    "        )\n",
    "        relative_position_bias = tf.keras.ops.transpose(relative_position_bias, (2, 0, 1))\n",
    "        attn = attn + tf.keras.ops.expand_dims(relative_position_bias, axis=0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            mask_float = tf.keras.ops.cast(\n",
    "                tf.keras.ops.expand_dims(tf.keras.ops.expand_dims(mask, axis=1), axis=0),\n",
    "                \"float32\",\n",
    "            )\n",
    "            attn = tf.keras.ops.reshape(attn, (-1, nW, self.number_of_heads, size, size)) + mask_float\n",
    "            attn = tf.keras.ops.reshape(attn, (-1, self.num_of_heads, size, size))\n",
    "            attn = tf.keras.activations.softmax(attn, axis=-1)\n",
    "        else:\n",
    "            attn = tf.keras.activations.softmax(attn, axis=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.keras.ops.transpose(x_qkv, (0, 2, 1, 3))\n",
    "        x_qkv = tf.keras.ops.reshape(x_qkv, (-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "        return x_qkv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1ee45-40c9-407d-a946-80e47e9886ca",
   "metadata": {},
   "source": [
    "#### Swin Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e9fbe8b4-0e7e-4205-bd25-8ae9aa74f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimension,\n",
    "        number_of_patches,\n",
    "        number_of_heads,\n",
    "        window_size=7,\n",
    "        shift_size=0,\n",
    "        number_of_MLP=1024,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.dimension = dimension  # number of input dimension\n",
    "        self.number_of_patches = number_of_patches  # number of embedded patches\n",
    "        self.number_of_heads = number_of_heads  # number of attention heads\n",
    "        self.window_size = window_size  # size of window\n",
    "        self.shift_size = shift_size  # size of window shift\n",
    "        self.number_of_MLP = number_of_MLP  # number of MLP nodes\n",
    "\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dimension,\n",
    "            window_size=(self.window_size, self.window_size),\n",
    "            number_of_heads=number_of_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "        self.drop_path = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(number_of_MLP),\n",
    "                tf.keras.layers.Activation(tf.keras.activations.gelu),\n",
    "                tf.keras.layers.Dropout(dropout_rate),\n",
    "                tf.keras.layers.Dense(dimension),\n",
    "                tf.keras.layers.Dropout(dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if min(self.number_of_patches) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.number_of_patches)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.number_of_patches\n",
    "            h_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            w_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.keras.ops.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.keras.ops.reshape(\n",
    "                mask_windows, [-1, self.window_size * self.window_size]\n",
    "            )\n",
    "            attn_mask = tf.keras.ops.expand_dims(mask_windows, axis=1) - tf.keras.ops.expand_dims(\n",
    "                mask_windows, axis=2\n",
    "            )\n",
    "            attn_mask = tf.keras.ops.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.keras.ops.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.keras.Variable(\n",
    "                initializer=attn_mask,\n",
    "                shape=attn_mask.shape,\n",
    "                dtype=attn_mask.dtype,\n",
    "                trainable=False,\n",
    "            )\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        height, width = self.number_of_patches\n",
    "        _, num_patches_before, channels = x.shape\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.keras.ops.reshape(x, (-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.keras.ops.roll(\n",
    "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.keras.ops.reshape(\n",
    "            x_windows, (-1, self.window_size * self.window_size, channels)\n",
    "        )\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.keras.ops.reshape(\n",
    "            attn_windows,\n",
    "            (-1, self.window_size, self.window_size, channels),\n",
    "        )\n",
    "        shifted_x = window_reverse(\n",
    "            attn_windows, self.window_size, height, width, channels\n",
    "        )\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.keras.ops.roll(\n",
    "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.keras.ops.reshape(x, (-1, height * width, channels))\n",
    "        x = self.drop_path(x, training=training)\n",
    "        x = x_skip + x\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa9d79-b0a2-44af-acc9-3ec2c238fa45",
   "metadata": {},
   "source": [
    "#### Patch Embed / Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f1befcba-2455-411d-8270-f312efaf0533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_extract(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
    "        strides=(1, patch_size[0], patch_size[1], 1),\n",
    "        rates=(1, 1, 1, 1),\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patch_dimension = patches.shape[-1]\n",
    "    patch_number = patches.shape[1]\n",
    "    return tf.reshape(patches, (batch_size, patch_number * patch_number, patch_dimension))\n",
    "\n",
    "\n",
    "class PatchEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, number_of_patches, embedding_dimension, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.number_of_patches = number_of_patches\n",
    "        self.proj = tf.keras.layers.Dense(embedding_dimension)\n",
    "        self.pos_embed = tf.keras.layers.Embedding(input_dim=number_of_patches, output_dim=embedding_dimension)\n",
    "\n",
    "    def call(self, patch):\n",
    "        pos = tf.keras.ops.arange(start=0, stop=self.number_of_patches)\n",
    "        return self.proj(patch) + self.pos_embed(pos)\n",
    "\n",
    "\n",
    "class PatchMerging(tf.keras.layers.Layer):\n",
    "    def __init__(self, number_of_patches, embedding_dimension):\n",
    "        super().__init__()\n",
    "        self.number_of_patches = number_of_patches\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.linear_trans = tf.keras.layers.Dense(2 * embedding_dimension, use_bias=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.number_of_patches\n",
    "        _, _, C = x.shape\n",
    "        x = tf.keras.ops.reshape(x, (-1, height, width, C))\n",
    "        x0 = x[:, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "        x = tf.keras.ops.concatenate((x0, x1, x2, x3), axis=-1)\n",
    "        x = tf.keras.ops.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
    "        return self.linear_trans(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebbeff7-f449-40c4-b40c-8cee43dd6105",
   "metadata": {},
   "source": [
    "### Training/Validation/Test Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ae553-362d-4fe7-bf92-c7cabf520070",
   "metadata": {},
   "source": [
    "#### Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "efba0e9d-c537-4492-8078-4b1a87116557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41276 files belonging to 16 classes.\n",
      "Using 28894 files for training.\n"
     ]
    }
   ],
   "source": [
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    verbose=True,\n",
    "    seed=seed_value,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e71b2d-e916-405f-8526-7022c7c2b334",
   "metadata": {},
   "source": [
    "#### Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2b1f8bf6-ea57-45b4-bcf7-f5820e051b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41276 files belonging to 16 classes.\n",
      "Using 12382 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=image_size,\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    verbose=True,\n",
    "    seed=seed_value,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05fb163-811c-4d91-a9b5-0088426a8039",
   "metadata": {},
   "source": [
    "#### Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f7c065c2-bd6a-4f82-86bc-d9c3db60a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_validation_batches = tf.data.experimental.cardinality(validation_set)\n",
    "test_set = validation_set.skip((number_of_validation_batches * 2) // 3)\n",
    "validation_set = validation_set.take((number_of_validation_batches * 2) // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a73e51e-98da-43bf-ba69-1bef20bb501e",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7c4f92a4-6d17-4e50-971d-da0e21fab58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_data = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f98c60b4-23b1-4d8b-a704-e190120b7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "training_set = training_set.map(lambda x, y: (augment_data(x, training=True), y))\n",
    "training_set = training_set.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_set = validation_set.map(lambda x, y: (x / 255.0, y)).prefetch(buffer_size=AUTOTUNE)\n",
    "test_set = test_set.map(lambda x, y: (x / 255.0, y)).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b607b3b-b82b-44f7-8001-a3247a0c955f",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a2f6d9ef-4b3b-40d9-ac83-c510d30e8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "60d7ba42-720c-4bda-aa03-5b7a402f3826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 256 values, but the requested shape requires a multiple of 1024 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 15\u001b[0m\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m PatchEmbedding(number_of_patches_x \u001b[38;5;241m*\u001b[39m number_of_patches_y, embedding_dimension)(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m SwinTransformer(\n\u001b[1;32m      5\u001b[0m     dimension\u001b[38;5;241m=\u001b[39membedding_dimension,\n\u001b[1;32m      6\u001b[0m     number_of_patches\u001b[38;5;241m=\u001b[39m(number_of_patches_x, number_of_patches_y),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39mdropout_rate,\n\u001b[1;32m     13\u001b[0m )(x)\n\u001b[0;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mSwinTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_patches_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_patches_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_of_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshift_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshift_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_MLP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_of_MLP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqkv_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqkv_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m PatchMerging((number_of_patches_x, number_of_patches_y), embedding_dimension\u001b[38;5;241m=\u001b[39membedding_dimension)(x)\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling1D()(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[128], line 72\u001b[0m, in \u001b[0;36mSwinTransformer.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     69\u001b[0m mask_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(mask_array)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# mask array to windows\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m mask_windows \u001b[38;5;241m=\u001b[39m \u001b[43mwindow_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m mask_windows \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m     74\u001b[0m     mask_windows, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size]\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     76\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mexpand_dims(mask_windows, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mexpand_dims(\n\u001b[1;32m     77\u001b[0m     mask_windows, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     78\u001b[0m )\n",
      "Cell \u001b[0;32mIn[126], line 5\u001b[0m, in \u001b[0;36mwindow_partition\u001b[0;34m(x, window_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m patch_num_y \u001b[38;5;241m=\u001b[39m height \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m window_size\n\u001b[1;32m      4\u001b[0m patch_num_x \u001b[38;5;241m=\u001b[39m width \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m window_size\n\u001b[0;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumber_of_patches_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumber_of_patches_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtranspose(x, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     17\u001b[0m windows \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape(x, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, window_size, window_size, channels))\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 256 values, but the requested shape requires a multiple of 1024 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "input = tf.keras.layers.Input(shape=(256, 12))\n",
    "print(number_of_patches_x, number_of_patches_y)\n",
    "x = PatchEmbedding(number_of_patches_x * number_of_patches_y, embedding_dimension)(input)\n",
    "x = SwinTransformer(\n",
    "    dimension=embedding_dimension,\n",
    "    number_of_patches=(number_of_patches_x, number_of_patches_y),\n",
    "    number_of_heads=number_of_heads,\n",
    "    window_size=window_size,\n",
    "    shift_size=0,\n",
    "    number_of_MLP=number_of_MLP,\n",
    "    qkv_bias=qkv_bias,\n",
    "    dropout_rate=dropout_rate,\n",
    ")(x)\n",
    "\n",
    "x = SwinTransformer(\n",
    "    dimension=embedding_dimension,\n",
    "    number_of_patches=(number_of_patches_x, number_of_patches_y),\n",
    "    number_of_heads=number_of_heads,\n",
    "    window_size=window_size,\n",
    "    shift_size=shift_size,\n",
    "    number_of_MLP=number_of_MLP,\n",
    "    qkv_bias=qkv_bias,\n",
    "    dropout_rate=dropout_rate,\n",
    ")(x)\n",
    "\n",
    "x = PatchMerging((number_of_patches_x, number_of_patches_y), embedding_dimension=embedding_dimension)(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "output = tf.keras.layers.Dense(number_of_classes, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e868f-9e7b-4df9-846d-4debd734435d",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12b862-f1f9-44b1-a05e-db176906df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccc3f1-981e-4eda-8bf4-ef1b2791c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2c8b6-5c8b-434d-b715-bf411fa089bb",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ed009-b115-4293-b26a-16a1c8f4b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(x=training_set, validation_data=validation_set, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d148038-e8e9-4a54-9d7c-3ec68f0c6942",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841e048-d774-4b58-8ae4-0349170ad2c9",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c590b-4f69-4f04-a822-47ee05b69fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"swin_model_trained.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162ad5a-85b4-4b1d-9593-493d9606e998",
   "metadata": {},
   "source": [
    "### Recording the training history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb28314-d1f6-471c-bb4d-27b0eb85682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_hist.json\", \"w\") as f:\n",
    "    json.dump(training_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efe7d3-ea04-46c9-8208-c0d6cdab205e",
   "metadata": {},
   "source": [
    "### Metrics Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba80660-3d09-4d94-873f-f6a4d1af4b06",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735dbe0-e9d1-4647-9221-c8ac5722d93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff6ef7a2-7da2-42db-8d1b-30fca18589e8",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f959c95-50cc-4842-aa06-78c82238f954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f83cca4-fb23-45e4-92d7-9eb17f8828cb",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b066a6e-7600-4a82-8f15-c54f33563fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39dd08-49dd-4ec1-b784-0e76165fda41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921b14d-f618-4208-92ec-426ce3b66e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b6965-acad-4c8d-9bf1-a7342748fdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da452d-062e-4feb-8de8-4101d5dc4bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba671dca-30c9-473f-bb95-ad25332fa780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd09c6-aeff-4a70-ad10-180a8d46d25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
